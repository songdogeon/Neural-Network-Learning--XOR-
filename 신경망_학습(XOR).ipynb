{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "신경망 학습(XOR)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songdogeon/Neural-Network-Learning--XOR-/blob/main/%EC%8B%A0%EA%B2%BD%EB%A7%9D_%ED%95%99%EC%8A%B5(XOR).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyjyu4FzUAVw"
      },
      "source": [
        "# 신경망 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQvNez4qydhL"
      },
      "source": [
        "## 단순한 신경망 구현 : Logic Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7te43hqyiiJ"
      },
      "source": [
        "### 필요한 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf2F_YbdybBE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orUoPmDcymhj"
      },
      "source": [
        "### 하이퍼 파라미터(Hyper Parameter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOAmMxo0ymDF"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjmLWgFVysnq"
      },
      "source": [
        "### 유틸 함수들(Util Functions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4OMFGrjyq1c"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1+ np.exp(-x))\n",
        "\n",
        "def mean_squeared_error(pred_y, true_y):\n",
        "  return 0.5 * (np.sum((true_y - pred_y)**2))\n",
        "\n",
        "def cross_entropy_error(pred_y, true_y):\n",
        "  if true_y.ndim == 1:\n",
        "    true_y = true_y.reshape(1, -1)\n",
        "    pred_y = true_y.reshape(1, -1)\n",
        "\n",
        "  delta = 1e-7\n",
        "  return -np.sum(true_y * np.log(pred_y + delta))\n",
        "\n",
        "def cross_entropy_error_for_batch(pred_y, true_y):\n",
        "  if true_y.ndim == 1:\n",
        "    true_y = true_y.reshape(1, -1)\n",
        "    pred_y = true_y.reshape(1, -1)\n",
        "  \n",
        "  delta = 1e-7\n",
        "  batch_size = pred_y.shape[0]\n",
        "  return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
        "\n",
        "def cross_entropy_error_for_bin(pred_y, true_y):\n",
        "  return 0.5 * np.sum((-true_y * np.log(pred_y) - (1- true_y) * np.log(1 - pred_y)))\n",
        "\n",
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "  \n",
        "  return y\n",
        "\n",
        "def differential(f, x):\n",
        "  eps = 1e-5\n",
        "  diff_value = np.zeros_like(x)\n",
        "\n",
        "  for i in range(x.shape[0]):\n",
        "    temp_val = x[i]\n",
        "\n",
        "    x[i] = temp_val + eps\n",
        "    f_h1 = f(x)\n",
        "\n",
        "    x[i] = temp_val - eps\n",
        "    f_h2 = f(x)\n",
        "\n",
        "    diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
        "    x[i] = temp_val\n",
        "\n",
        "  return diff_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Z2LTT_y3i5"
      },
      "source": [
        "### 신경망"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMTjjYgdy3D8"
      },
      "source": [
        "class LogicGateNet():\n",
        "\n",
        "  def __init__(self):\n",
        "    def weight_init():\n",
        "      np.random.seed(1)\n",
        "      weights = np.random.randn(2)\n",
        "      bias = np.random.rand(1)\n",
        "\n",
        "      return weights, bias\n",
        "\n",
        "    self.weights, self.bias = weight_init()\n",
        "\n",
        "  def predict(self, x):\n",
        "    W = self.weights.reshape(-1, 1)\n",
        "    b = self.bias\n",
        "\n",
        "    pred_y = sigmoid(np.dot(x, W) + b)\n",
        "    return pred_y\n",
        "\n",
        "  def loss(self, x, true_y):\n",
        "    pred_y = self.predict(x)\n",
        "    return cross_entropy_error_for_bin(pred_y, true_y)\n",
        "\n",
        "  def get_gradient(self, x, t):\n",
        "    def loss_grad(grad):\n",
        "      return self.loss(x, t)\n",
        "\n",
        "    grad_W = differential(loss_grad, self.weights)\n",
        "    grad_B = differential(loss_grad, self.bias)\n",
        "\n",
        "    return grad_W, grad_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbNDoH_3zbGZ"
      },
      "source": [
        "### AND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P-ib8_RzHTh"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRiaACA6zGom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8258d237-2939-413b-b213-2deb553b322d"
      },
      "source": [
        "AND = LogicGateNet()\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [0], [0], [1]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = AND.get_gradient(X, Y)\n",
        "\n",
        "  AND.weights -= lr * grad_W\n",
        "  AND.bias -= lr * grad_B\n",
        "  \n",
        "  loss = AND.loss(X, Y)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, AND.weights, AND.bias))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 0.6886489498077508, Weights: [1.56426876 0.79168393], Bias: [-2.14871589]\n",
            "Epoch: 200, Cost: 0.4946368603067626, Weights: [2.01360719 1.71241131], Bias: [-3.07894028]\n",
            "Epoch: 300, Cost: 0.3920165980751678, Weights: [2.42841657 2.29753793], Bias: [-3.79103207]\n",
            "Epoch: 400, Cost: 0.3257214374794629, Weights: [2.794852   2.73235738], Bias: [-4.37257095]\n",
            "Epoch: 500, Cost: 0.2786360133470194, Weights: [3.11636193 3.08408364], Bias: [-4.86571237]\n",
            "Epoch: 600, Cost: 0.24328504683857205, Weights: [3.40015395 3.38235762], Bias: [-5.29433736]\n",
            "Epoch: 700, Cost: 0.2157253655246455, Weights: [3.65300561 3.64264217], Bias: [-5.67349792]\n",
            "Epoch: 800, Cost: 0.19363244428376314, Weights: [3.88044124 3.87412053], Bias: [-6.01340133]\n",
            "Epoch: 900, Cost: 0.175532131279099, Weights: [4.08680123 4.08279091], Bias: [-6.32133891]\n",
            "Epoch: 1000, Cost: 0.16043926933305935, Weights: [4.27548114 4.27284863], Bias: [-6.6027234]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZoyQv_czT7R"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7CvWgc9zREa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60de9310-ae5e-41a9-9d1d-d3fe312d77d2"
      },
      "source": [
        "print(AND.predict(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00135483]\n",
            " [0.08867878]\n",
            " [0.08889176]\n",
            " [0.87496677]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMXNiXWzts-"
      },
      "source": [
        "### OR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ79pc4jzw3O"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gnLmAyQzuoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b57dbb-bda1-4e69-9fde-d5b61f73afaa"
      },
      "source": [
        "OR = LogicGateNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_2 = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = OR.get_gradient(X, Y_2)\n",
        "\n",
        "  OR.weights -= lr * grad_W\n",
        "  OR.bias -= lr * grad_B\n",
        "\n",
        "  loss = OR.loss(X, Y_2)\n",
        "  train_loss_list.append(loss)\n",
        "  \n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, OR.weights, OR.bias))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 0.49580923848037245, Weights: [2.45484353 1.40566594], Bias: [-0.14439625]\n",
            "Epoch: 200, Cost: 0.3398674231512476, Weights: [2.98631846 2.39448393], Bias: [-0.67661178]\n",
            "Epoch: 300, Cost: 0.2573360986184237, Weights: [3.45016595 3.08431266], Bias: [-1.03721585]\n",
            "Epoch: 400, Cost: 0.20630142190061632, Weights: [3.85230067 3.60865952], Bias: [-1.30598633]\n",
            "Epoch: 500, Cost: 0.1716549922114765, Weights: [4.20195872 4.03000824], Bias: [-1.52060015]\n",
            "Epoch: 600, Cost: 0.14665018845489367, Weights: [4.50867681 4.38171478], Bias: [-1.6994397]\n",
            "Epoch: 700, Cost: 0.12779768649443757, Weights: [4.78049264 4.68334611], Bias: [-1.8527641]\n",
            "Epoch: 800, Cost: 0.11310517185394649, Weights: [5.0237707 4.9472786], Bias: [-1.98691756]\n",
            "Epoch: 900, Cost: 0.10135180918369109, Weights: [5.24347159 5.18181684], Bias: [-2.10611973]\n",
            "Epoch: 1000, Cost: 0.09174843008614507, Weights: [5.44346811 5.39279833], Bias: [-2.21332947]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWmEtX_VnLSI"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwPpOs3-z2vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951f42c7-21cc-4c47-8840-8efa09e41ad6"
      },
      "source": [
        "print(OR.predict(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09855987]\n",
            " [0.9600543 ]\n",
            " [0.96195283]\n",
            " [0.9998201 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEBhczCIz57Q"
      },
      "source": [
        "### NAND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzQaaHKKz8sZ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h463QUQRz8PS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9290a693-f103-4a2a-ba8d-2c558dd982cb"
      },
      "source": [
        "NAND = LogicGateNet()\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_3 = np.array([[1], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = NAND.get_gradient(X, Y_3)\n",
        "\n",
        "  NAND.weights -= lr * grad_W\n",
        "  NAND.bias -= lr * grad_B\n",
        "  \n",
        "  loss = NAND.loss(X, Y_3)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, NAND.weights, NAND.bias))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 0.7911738653764443, Weights: [-0.48972722 -1.25798774], Bias: [1.74566135]\n",
            "Epoch: 200, Cost: 0.5430490957875922, Weights: [-1.51545093 -1.80261804], Bias: [2.79151756]\n",
            "Epoch: 300, Cost: 0.42125913027366896, Weights: [-2.14614496 -2.26642639], Bias: [3.56506179]\n",
            "Epoch: 400, Cost: 0.3456117101528016, Weights: [-2.607325   -2.66303355], Bias: [4.18521187]\n",
            "Epoch: 500, Cost: 0.293129860518541, Weights: [-2.97696333 -3.00501941], Bias: [4.70528682]\n",
            "Epoch: 600, Cost: 0.2543396786003746, Weights: [-3.28850585 -3.30365261], Bias: [5.1539571]\n",
            "Epoch: 700, Cost: 0.22443918596780807, Weights: [-3.55912171 -3.56778782], Bias: [5.54869527]\n",
            "Epoch: 800, Cost: 0.20067626330797955, Weights: [-3.7989077  -3.80411461], Bias: [5.90108417]\n",
            "Epoch: 900, Cost: 0.1813412551760061, Weights: [-4.01441395 -4.01767547], Bias: [6.21926514]\n",
            "Epoch: 1000, Cost: 0.16530944081725432, Weights: [-4.21019696 -4.21231432], Bias: [6.50920952]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR-rHaTU0Mga"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpzKW6sm0Ghp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15e83aa-a6d4-43d8-c84b-db67db02f32a"
      },
      "source": [
        "print(NAND.predict(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99851256]\n",
            " [0.90861957]\n",
            " [0.90879523]\n",
            " [0.12861037]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTWfSQ60Zl2"
      },
      "source": [
        "### XOR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmmL0VIu0bXq"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CGm0r1M0a9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a51ce5b-5592-4ae2-de3c-d0e31c849b5e"
      },
      "source": [
        "XOR = LogicGateNet()\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_4 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = XOR.get_gradient(X, Y_4)\n",
        "\n",
        "  XOR.weights -= lr * grad_W\n",
        "  XOR.bias -= lr * grad_B\n",
        "  \n",
        "  loss = XOR.loss(X, Y_4)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, XOR.weights, XOR.bias))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 1.402685224545991, Weights: [ 0.47012771 -0.19931523], Bias: [-0.16097708]\n",
            "Epoch: 200, Cost: 1.3879445622846385, Weights: [ 0.1572739  -0.03387161], Bias: [-0.07321056]\n",
            "Epoch: 300, Cost: 1.386492030048373, Weights: [0.05525161 0.00089673], Bias: [-0.03330094]\n",
            "Epoch: 400, Cost: 1.3863236205351996, Weights: [0.02049628 0.00504503], Bias: [-0.01514784]\n",
            "Epoch: 500, Cost: 1.386299474364679, Weights: [0.0080051  0.00361297], Bias: [-0.00689034]\n",
            "Epoch: 600, Cost: 1.3862953430687444, Weights: [0.00326661 0.00201812], Bias: [-0.00313421]\n",
            "Epoch: 700, Cost: 1.3862945581495083, Weights: [0.00137938 0.00102449], Bias: [-0.00142566]\n",
            "Epoch: 800, Cost: 1.38629440139037, Weights: [0.00059716 0.00049628], Bias: [-0.00064849]\n",
            "Epoch: 900, Cost: 1.3862943694120307, Weights: [0.00026303 0.00023435], Bias: [-0.00029498]\n",
            "Epoch: 1000, Cost: 1.386294362832352, Weights: [0.0001172  0.00010905], Bias: [-0.00013418]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy-ktElI0o5P"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWAJAJ_T0oqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d954a47d-0dd4-4a51-e943-f35195ea5705"
      },
      "source": [
        "print(XOR.predict(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.49996646]\n",
            " [0.49999372]\n",
            " [0.49999575]\n",
            " [0.50002302]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlq_-6E1nIq"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(1)\n",
        "\n",
        "- 얕은 신경망, Shallow Neural Network\n",
        "\n",
        "- 두 논리게이트(NAND, OR)를 통과하고  \n",
        "  AND 게이트로 합쳐서 구현\n",
        "\n",
        "- 06 신경망 구조 참고"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr7nYMG20jTo"
      },
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_5 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "s1 = NAND.predict(X)\n",
        "s2 = OR.predict(X)\n",
        "X_2 = np.array([s1, s2]).T.reshape(-1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkTDx8Ah1xHY"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK2iD5A91yWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7dc402-d5fd-42bc-e800-4b4e9a3fee09"
      },
      "source": [
        "print(AND.predict(X_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.12870357]\n",
            " [0.79966936]\n",
            " [0.80108545]\n",
            " [0.14420781]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-SK4G262Agn"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(2)\n",
        "- 클래스로 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RpnHCRZ1zwr"
      },
      "source": [
        "class XORNet():\n",
        "\n",
        "  def __init__(self):\n",
        "    np.random.seed(1)\n",
        "\n",
        "    def weight_init():\n",
        "      params = {}\n",
        "      params['w_1'] = np.random.randn(2)\n",
        "      params['b_1'] = np.random.rand(2)\n",
        "      params['w_2'] = np.random.randn(2)\n",
        "      params['b_2'] = np.random.rand(1)\n",
        "      return params\n",
        "\n",
        "    self.params = weight_init()\n",
        "\n",
        "  def predict(self, x):\n",
        "    W_1, W_2 = self.params['w_1'].reshape(-1, 1), self.params['w_2'].reshape(-1, 1)\n",
        "    B_1, B_2 = self.params['b_1'], self.params['b_2']\n",
        "\n",
        "    A1 = np.dot(x, W_1) + B_1\n",
        "    Z1 = sigmoid(A1)\n",
        "    A2 = np.dot(Z1, W_2) + B_2\n",
        "    pred_y = sigmoid(A2)\n",
        "\n",
        "    return pred_y\n",
        "\n",
        "  def loss(self, x, true_y):\n",
        "    pred_y = self.predict(x)\n",
        "    return cross_entropy_error_for_bin(pred_y, true_y)\n",
        "\n",
        "  def get_gradient(self, x, t):\n",
        "    def loss_grad(grad):\n",
        "      return self.loss(x, t)\n",
        "\n",
        "    grads = {}\n",
        "    grads['w_1'] = differential(loss_grad, self.params['w_1'])\n",
        "    grads['b_1'] = differential(loss_grad, self.params['b_1'])\n",
        "    grads['w_2'] = differential(loss_grad, self.params['w_2'])\n",
        "    grads['b_2'] = differential(loss_grad, self.params['b_2'])\\\n",
        "\n",
        "    return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lplK_x0l2YLh"
      },
      "source": [
        "#### 하이퍼 파라미터(Hyper Parameter)\n",
        "- 재조정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf-3wWSv2b7l"
      },
      "source": [
        "lr = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmHKd45d2JbJ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQNd3XVd2Gj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16db1b3-d464-4ba1-80f0-ba8ed78bf9d9"
      },
      "source": [
        "XOR = XORNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_5 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grads = XOR.get_gradient(X, Y_5)\n",
        "\n",
        "  for key in ('w_1', 'b_1', 'w_2', 'b_2'):\n",
        "    XOR.params[key] -= lr * grads[key]\n",
        "\n",
        "  loss = XOR.loss(X, Y_5)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}\".format(i+1, loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 1.353561444245376\n",
            "Epoch: 200, Cost: 1.2827154568291983\n",
            "Epoch: 300, Cost: 0.8968907892231803\n",
            "Epoch: 400, Cost: 0.338719714121707\n",
            "Epoch: 500, Cost: 0.18121344476204979\n",
            "Epoch: 600, Cost: 0.11991186457349581\n",
            "Epoch: 700, Cost: 0.08861936864730534\n",
            "Epoch: 800, Cost: 0.0699218065308316\n",
            "Epoch: 900, Cost: 0.05758041353096763\n",
            "Epoch: 1000, Cost: 0.0488609356844432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIV_GsoG2eDs"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpr0nZhc2Szr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3c1b9b-d465-4413-df22-4ec143da4174"
      },
      "source": [
        "print(XOR.predict(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0217367 ]\n",
            " [0.96884394]\n",
            " [0.97816819]\n",
            " [0.0217794 ]]\n"
          ]
        }
      ]
    }
  ]
}